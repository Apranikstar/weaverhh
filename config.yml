# config.yaml
network: ParticleTransformer
data:
  # The ROOT file(s) and tree
  files:
    - path/to/your_file.root
      tree_name: Events  # change this if your TTree has a different name

  # How many jets per batch to load
  batch_size: 512
  fetch_step: 1

  # Jet-level variables (global features)
  global_features:
    - jet_p
    - jet_e
    - jet_mass
    - jet_phi
    - jet_theta
    - jet_nconst
    - jet_nmu
    - jet_nel
    - jet_nchad
    - jet_ngamma
    - jet_nnhad
    - jet_npfcand

  # Constituent-level (per-particle) features
  pf_features:
    - pfcand_erel_log
    - pfcand_thetarel
    - pfcand_phirel
    - pfcand_dptdpt
    - pfcand_detadeta
    - pfcand_dphidphi
    - pfcand_dxydxy
    - pfcand_dzdz
    - pfcand_dxydz
    - pfcand_dphidxy
    - pfcand_dlambdadz
    - pfcand_dxyc
    - pfcand_dxyctgtheta
    - pfcand_phic
    - pfcand_phidz
    - pfcand_phictgtheta
    - pfcand_cdz
    - pfcand_cctgtheta
    - pfcand_mtof
    - pfcand_dndx
    - pfcand_charge
    - pfcand_isMu
    - pfcand_isEl
    - pfcand_isChargedHad
    - pfcand_isGamma
    - pfcand_isNeutralHad
    - pfcand_type
    - pfcand_dxy
    - pfcand_dz
    - pfcand_btagSip2dVal
    - pfcand_btagSip2dSig
    - pfcand_btagSip3dVal
    - pfcand_btagSip3dSig
    - pfcand_btagJetDistVal
    - pfcand_btagJetDistSig
    - pfcand_e
    - pfcand_p
    - pfcand_theta
    - pfcand_phi

  # The label (target) for supervised learning; choose one or more of these
  labels:
    - recojet_isG
    - recojet_isQ
    - recojet_isS
    - recojet_isC
    - recojet_isB
    - recojet_isTAU

model:
  input_dim: 43   # number of per-particle features above
  global_input_dim: 12  # number of global features
  num_classes: 6  # number of labels in multi-class classification
  # You can add more model hyperparameters if needed

training:
  num_epochs: 20
  learning_rate: 1e-3
  optimizer: adam
  scheduler: linear
  weight_decay: 0.01
  patience: 3

logging:
  save_dir: ./checkpoints
  log_every: 10
  eval_every: 1

